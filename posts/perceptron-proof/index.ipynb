{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a5c7528a-4751-4b2f-9048-f59bbf1b5d5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "title: Mathematical Proof of the Perceptron Learning Rule\n",
    "author: Neil Dcruze\n",
    "date: '2023-03-01'\n",
    "image: \"image.jpg\"\n",
    "description: \"Using Mathematics to prove why the Perceptron Learning Rule works\"\n",
    "format: html\n",
    "categories: [\"Machine Learning\", \"Mathematics\"]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edba7fc-712d-43ea-bc28-25a6b30b804d",
   "metadata": {},
   "source": [
    "# Perceptron Learning Rule\n",
    "The Perceptron Learning Rule is based on an update which only happens when the activation (related to the predicted label) is different from the actual label. In the situation where the activation and the actual label are the same, no update takes places!\n",
    "\n",
    "The learning rule is based on the following mathematical formula:\n",
    "$$\n",
    "w_{d} = w_{d} + yx{_d} \n",
    "$$\n",
    "$$\n",
    "b = b + y\n",
    "$$\n",
    "where y is the actual label value!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4315e62-be4a-48c9-ab8c-2460d5d4a3cd",
   "metadata": {},
   "source": [
    "We have current parameters,\n",
    "$$\n",
    "w = (w_1, w_2, w_3,....., w_d)\n",
    "$$\n",
    "$$\n",
    "\\text{where  } w \\in \\mathbb{R}^{d} \n",
    "$$\n",
    "$$\n",
    "b \\rightarrow \\text{bias}\n",
    "$$\n",
    "\n",
    "For an example: $(x, y)$ where $x \\in \\mathbb{R}^{d}$ and $d$ = number of features, and $y = \\pm 1$ is the true label!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fa467-70d8-42a6-8129-df8ee2dd46af",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">When Actual Label: $y = +1$ but Activation: $a < 0$ </font>\n",
    "Let us say, an example is of a positive label: $y = +1$, but our activation is wrong, $a < 0$!\n",
    "\n",
    "Updating the weights and bias, we have a modified weight vector $w^{'}$ and a modified bias $b^{'}$:\n",
    "$w^{'} = (w_{1}^{'}, w_{2}^{'}, w_{3}^{'},......, w_{d}^{'})$ and $b^{'}$\n",
    "\n",
    "When we observe the same example again, we compute the new activation $a^{'}$:\n",
    "\n",
    "$$\n",
    "a^{'} = \\sum_{d = 1}^{D}w_{d}^{'}x_{d} + b^{'} = \\sum_{d = 1}^{D}(w_{d} + yx_{d})x_{d} + (b + y)\n",
    "$$\n",
    "\n",
    "Since, $y = +1$:\n",
    "$$\n",
    "a^{'} = \\sum_{d = 1}^{D}(w_{d} + x_{d})x_{d} + (b + 1)\n",
    "$$\n",
    "$$\n",
    "= \\sum_{d = 1}^{D}w_{d}x_{d} + \\sum_{d = 1}^{D}(x_{d})^{2} + b + 1\n",
    "$$\n",
    "$$\n",
    "= [\\sum_{d = 1}^{D}w_{d}x_{d} + b] + \\sum_{d = 1}^{D}(x_{d})^{2} + 1\n",
    "$$\n",
    "\n",
    "Since, $a \\text{ (the old activation)}$ = $\\sum_{d = 1}^{D}w_{d}x_{d} + b$, we have:\n",
    "$$\n",
    "a^{'} = a + \\sum_{d = 1}^{D}(x_{d})^{2} + 1 \\text{ which makes } a^{'} > a\n",
    "$$\n",
    "Since, $(x_d)^{2} \\geq 0$, $a^{'}$ is always at least 1 more than $a$. Since our activation a was $a < 0$, and $y$ was $y = +1$, we have successfully moved $a^{'}$ in the right direction i.e. towards positive!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86654b7f-af1b-444c-ada3-7f24b139015d",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">When Actual Label: $y = -1$ but Activation: $a > 0$ </font>\n",
    "Let us say, an example is of a positive label: $y = -1$, but our activation is wrong, $a > 0$!\n",
    "\n",
    "Updating the weights and bias, we have a modified weight vector $w^{'}$ and a modified bias $b^{'}$:\n",
    "$w^{'} = (w_{1}^{'}, w_{2}^{'}, w_{3}^{'},......, w_{d}^{'})$ and $b^{'}$\n",
    "\n",
    "When we observe the same example again, we compute the new activation $a^{'}$:\n",
    "\n",
    "$$\n",
    "a^{'} = \\sum_{d = 1}^{D}w_{d}^{'}x_{d} + b^{'} = \\sum_{d = 1}^{D}(w_{d} + yx_{d})x_{d} + (b + y)\n",
    "$$\n",
    "\n",
    "Since, $y = -1$:\n",
    "$$\n",
    "a^{'} = \\sum_{d = 1}^{D}(w_{d} - x_{d})x_{d} + (b - 1)\n",
    "$$\n",
    "$$\n",
    "= \\sum_{d = 1}^{D}w_{d}x_{d} - \\sum_{d = 1}^{D}(x_{d})^{2} + b - 1 \n",
    "$$\n",
    "$$\n",
    "= [\\sum_{d = 1}^{D}w_{d}x_{d} + b] - [\\sum_{d = 1}^{D}(x_{d})^{2} + 1]\n",
    "$$\n",
    "\n",
    "Since, $a \\text{ (the old activation)}$ = $\\sum_{d = 1}^{D}w_{d}x_{d} + b$, we have:\n",
    "$$\n",
    "a^{'} = a - [\\sum_{d = 1}^{D}(x_{d})^{2} + 1] \\text{ which makes } a^{'} < a\n",
    "$$\n",
    "Since, $(x_d)^{2} \\geq 0$, $a^{'}$ is always at least 1 less than $a$. Since our activation a was $a > 0$, and $y$ was $y = -1$, we have successfully moved $a^{'}$ in the right direction i.e. towards negative!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
