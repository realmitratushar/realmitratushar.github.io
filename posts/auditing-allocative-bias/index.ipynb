{
 "cells": [
  {
   "cell_type": "raw",
   "id": "54c1e703-fc78-4ad6-8959-47816599fa8d",
   "metadata": {},
   "source": [
    "---\n",
    "title: Auditing Allocative Bias\n",
    "author: Neil Dcruze\n",
    "date: '2023-03-28'\n",
    "image: \"image.png\"\n",
    "description: \"Training a Model to predict Employment for Different Individuals and then Audit the Model to Display Potential Biases across different Racial Groups\"\n",
    "format: html\n",
    "categories: \"Machine Learning\" \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd75d72-3f47-466a-b3e5-895da0bb97d5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In machine learning, <i>bias</i> refers to the production of consistently prejudiced outcomes by the algorithm, which can create unfair circumstances on multiple fronts. In this blog post, we aim to explore that <i>bias</i> by:\n",
    "<ol>\n",
    "    <li> Creating a machine learning model that predicts an individual characteristic like: employment status or income, on the basis of other demographic characteristics\n",
    "    <li> Performing a \"fairness audit\" in order to assess whether our algorithm displays bias with respect to demographic characteristics (race or sex)\n",
    "</ol>\n",
    "\n",
    "For the purpose of this blog post, we will be using the <u>folktables</u> package to download data on which we will perform the <i>bias audit</i>. Here, we will be using the data of individuals from the state of New York!\n",
    "\n",
    "# Loading and Setting Up the Data\n",
    "First, let us load the data and prepare it for our purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9bd5202-7756-4722-b2c8-0c0d3b904068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2018 1-Year person survey for NY...\n"
     ]
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment, BasicProblem, adult_filter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "STATE = 'NY'\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "\n",
    "acs_data = data_source.get_data(states=[STATE], download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e7403-6899-44f1-8d46-875ee67360cf",
   "metadata": {},
   "source": [
    "Now, let us examine the first few rows of the data, to get an idea of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d314d519-56cb-477c-96cd-e0eba72e564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>SPORDER</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>...</th>\n",
       "      <th>PWGTP71</th>\n",
       "      <th>PWGTP72</th>\n",
       "      <th>PWGTP73</th>\n",
       "      <th>PWGTP74</th>\n",
       "      <th>PWGTP75</th>\n",
       "      <th>PWGTP76</th>\n",
       "      <th>PWGTP77</th>\n",
       "      <th>PWGTP78</th>\n",
       "      <th>PWGTP79</th>\n",
       "      <th>PWGTP80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3802</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1013097</td>\n",
       "      <td>145</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>21</td>\n",
       "      <td>146</td>\n",
       "      <td>265</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000040</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2702</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1013097</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000060</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1013097</td>\n",
       "      <td>88</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>163</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>162</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000081</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2401</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1013097</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>111</td>\n",
       "      <td>107</td>\n",
       "      <td>17</td>\n",
       "      <td>196</td>\n",
       "      <td>109</td>\n",
       "      <td>200</td>\n",
       "      <td>198</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>2018GQ0000103</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1400</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1013097</td>\n",
       "      <td>83</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>154</td>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>83</td>\n",
       "      <td>152</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 286 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RT       SERIALNO  DIVISION  SPORDER  PUMA  REGION  ST   ADJINC  PWGTP  \\\n",
       "0  P  2018GQ0000012         2        1  3802       1  36  1013097    145   \n",
       "1  P  2018GQ0000040         2        1  2702       1  36  1013097     43   \n",
       "2  P  2018GQ0000060         2        1  2001       1  36  1013097     88   \n",
       "3  P  2018GQ0000081         2        1  2401       1  36  1013097    109   \n",
       "4  P  2018GQ0000103         2        1  1400       1  36  1013097     83   \n",
       "\n",
       "   AGEP  ...  PWGTP71  PWGTP72  PWGTP73  PWGTP74  PWGTP75  PWGTP76  PWGTP77  \\\n",
       "0    26  ...      146      146       21       24      266      263       21   \n",
       "1    21  ...        6       42       43        7       40        6       43   \n",
       "2    18  ...       88      163      161      162       87       12      162   \n",
       "3    85  ...       17       15      111      107       17      196      109   \n",
       "4    19  ...       81       12       80      154       12       80       12   \n",
       "\n",
       "   PWGTP78  PWGTP79  PWGTP80  \n",
       "0      146      265      144  \n",
       "1       40       42        6  \n",
       "2       88       87       88  \n",
       "3      200      198      111  \n",
       "4       83      152      154  \n",
       "\n",
       "[5 rows x 286 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54c0ae-c958-49bb-b43c-616e85064dc7",
   "metadata": {},
   "source": [
    "Each row in the above dataset corresponds to an individual citizen of New York who filled out the PUMS survey of 2018. Therefore, what we have is a $n$x$p$ matrix, where $n$ = number of data points, and $p$ = number of features. We can see that there are a bunch of features in this dataset, and all of them might not be pertinent for our analysis. Therefore, we are only going to choose the features which are relevant for this blog post: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "082f31fb-478c-4385-a1d1-7aacefe47885",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_features=['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ba3f6-9e1f-42b2-8ac4-ea10e644dc36",
   "metadata": {},
   "source": [
    "Now, since we want to predict <i>ESR</i> - Employment Status, based on every relevant feature except the <i>RAC1P</i> - Race, we want to remove these two features from the list of <i>possible_features</i>. This is because one of these features is our target (output), and the we are excluding the other one (race) to study racial bias in our machine learning model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66a54cb-f3d5-426c-9f5c-791fe662dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [f for f in possible_features if f not in [\"ESR\", \"RAC1P\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8328d48-fde6-451e-bd42-82fb1b606c0f",
   "metadata": {},
   "source": [
    "Now that we know:\n",
    "<ol>\n",
    "    <li> Features (features_to_use): the features we wish to use for the prediction\n",
    "    <li> Target (ESR): the thing we are trying to predict\n",
    "    <li> Group (RAC1P): the group by which we wish to audit the bias\n",
    "</ol>\n",
    "\n",
    "We can go ahead and create a <i>BasicProblem</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a729f3b9-3d2f-42a7-921e-5365d1724a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmploymentProblem = BasicProblem(\n",
    "    features=features_to_use,\n",
    "    target='ESR',\n",
    "    target_transform=lambda x: x == 1,\n",
    "    group='RAC1P',\n",
    "    preprocess=lambda x: x,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b0486-258f-445b-8f3b-c1a781317a2d",
   "metadata": {},
   "source": [
    "Now we can go ahead and extract our feature matrix, output labels vector, and the group (race) vector as numpy objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76af7561-c21a-4ff6-b48f-e408a4ed4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, label, group = EmploymentProblem.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c92bc-904c-49f9-87e7-96b8b93b14ce",
   "metadata": {},
   "source": [
    "Now, that we have all the necessary data, we can split our data into <i>training data</i> and <i>testing data</i>. Here, 80% of the data will be used for training and the remaining 20% will be used for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d3f2a3d-3f10-47fd-8d23-98ae03366842",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(features, label, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78632e8-07de-4eac-bd63-711aa81cefeb",
   "metadata": {},
   "source": [
    "# Basic Descriptives\n",
    "Now, that we have our data set up, we can address some basic descriptives of the data which will aid us in our analysis later on. For this it is useful to make a <i>data frame</i> out of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c1ca9eb-7e32-4ac2-940d-3e429e912894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train, columns = features_to_use)\n",
    "df[\"group\"] = group_train\n",
    "df[\"label\"] = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99716421-86ad-408a-8204-13e10dbb3781",
   "metadata": {},
   "source": [
    "Question 1: How many individuals are in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6671ab5-d725-458f-a204-9be467dff1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: There are 157573 people in the training data set!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Answer 1: There are {df.shape[0]} people in the training data set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8172e-fadc-4305-85db-1ec0d1455eb8",
   "metadata": {},
   "source": [
    "Question 2: Of these individuals, what proportion have target label equal to 1? In employment prediction, these would correspond to employed individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07676014-4223-4604-81a7-2065d0e6a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2: There are 73262 number of people in the training data set who are employed - have target label equal to True!\n"
     ]
    }
   ],
   "source": [
    "employed = df[df['label']==True]\n",
    "print(f\"Answer 2: There are {employed.shape[0]} number of people in the training data set who are employed - have target label equal to True!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc50160-0bfa-4cae-a2cc-328c7ad983e0",
   "metadata": {},
   "source": [
    "Question 3: Of these individuals, how many are in each of the groups?\n",
    "<br><br>Answer 3: We can see a breakdown of how many people of each racial group are employed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "049ef13b-f705-4c78-919c-efe3b6210141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group\n",
      "1    52646\n",
      "2     8030\n",
      "3      177\n",
      "4        3\n",
      "5       66\n",
      "6     6778\n",
      "7       23\n",
      "8     3860\n",
      "9     1679\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(employed.groupby('group').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349d9341-9ea0-49ec-a912-d73ccfe78980",
   "metadata": {},
   "source": [
    "Question 4: In each group, what proportion of individuals have target label equal to 1?\n",
    "<br><br>Answer 4: The proportion of individuals in each group who are employed (have target label 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b607e70f-3d45-4a3a-932e-6093be7c268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label\n",
      "       mean\n",
      "group      \n",
      "1      0.47\n",
      "2      0.42\n",
      "3      0.43\n",
      "4      0.75\n",
      "5      0.34\n",
      "6      0.50\n",
      "7      0.42\n",
      "8      0.44\n",
      "9      0.37\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['group'])[['label']].aggregate([np.mean]).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c0b43-7d36-492e-b081-0e7177ce0a4b",
   "metadata": {},
   "source": [
    "Question 5: Check for intersectional trends by studying the proportion of positive target labels broken out by your chosen group labels and an additional group label. For example, if you chose race (RAC1P) as your group, then you could also choose sex (SEX) and compute the proportion of positive labels by both race and sex. \n",
    "<br><br> Answer 5: For answering this question, first let us look at the positive labels broken down only by SEX. Then we can look at the intersectionality of RACE and SEX, by looking at positive labels broken down by these two group labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "341558bb-4b00-4dad-8447-c8d1643161ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label\n",
      "     mean\n",
      "SEX      \n",
      "1.0  0.49\n",
      "2.0  0.44\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['SEX'])[['label']].aggregate([np.mean]).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632494b-3c2d-496a-aca9-f35c6745db66",
   "metadata": {},
   "source": [
    "We can see that: 49% of MEN (1.0) are employed, while 44% of WOMEN (2.0) are employed! Now let us look at the positive target labels broken down by both RACE and SEX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43b1fc53-d236-4520-b31e-e96be7072ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          label\n",
      "           mean\n",
      "group SEX      \n",
      "1     1.0  0.50\n",
      "      2.0  0.45\n",
      "2     1.0  0.40\n",
      "      2.0  0.44\n",
      "3     1.0  0.46\n",
      "      2.0  0.39\n",
      "4     1.0  1.00\n",
      "      2.0  0.50\n",
      "5     1.0  0.39\n",
      "      2.0  0.29\n",
      "6     1.0  0.54\n",
      "      2.0  0.46\n",
      "7     1.0  0.35\n",
      "      2.0  0.50\n",
      "8     1.0  0.48\n",
      "      2.0  0.41\n",
      "9     1.0  0.36\n",
      "      2.0  0.38\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['group','SEX'])[['label']].aggregate([np.mean]).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70164be5-01c6-4380-840d-6d8fbeda854f",
   "metadata": {},
   "source": [
    "We can visualize this data using a bar chart for easier understanding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "672435b7-7e55-4d60-9957-7a1429f769d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bplot = sns.barplot(data=df, x=\"group\", y=\"label\", hue=\"SEX\", errorbar=('ci', 0))\n",
    "bplot.set(xlabel=\"Different Racial Groups\", ylabel=\"Proportion of People Employed\")\n",
    "plt.show(bplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd653235-a322-49d7-8f4c-195f58d8ef98",
   "metadata": {},
   "source": [
    "Therefore, it is apparent that the proportion of women who are employed, is less than the proportion of men who are employed, in almost all racial groups except racial group 2, 7, and 9. Not only that, some racial groups have a really high disparity between the proportion of men who are employed versus the proportion of women who are employed. For instance, in racial group 4: the proportion of men who are employed is roughly 100%, while the proportion of women who are employed is only 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b8f9c-fd88-4039-b313-17b5e0a9f4fc",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "Now that we have answered the basic descriptive questions, we are ready to train our model on the training data. For this blog post, the chosen machine learning model is: <i>Logistic Regression</i>, and we will be tuning the polynomial features (number of degrees) in our <i>Logistic Regression</i> model. Therefore, our workflow is going to be:\n",
    "<ol>\n",
    "    <li> Creating a function that will utilize <i>Pipeline</i> to make it easier for us to construct a <i>Logistic Regression</i> model with certain number of polynomial features (a certain number of degrees)\n",
    "    <li> Using cross-validation to select the best degree (number of polynomial features)\n",
    "    <li> Creating a Logistic Regression model with the best number of degrees that we found in Step (2) and fitting it on our <i>training data</i>\n",
    "    <li> Checking the performance of our model on the <i>testing data</i>\n",
    "</ol>\n",
    "\n",
    "Let us get started with creating the function which utilizes Pipeline, for easier construction of our Logistic Regression models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2a9da23-bc80-4061-be05-d3a01f9f16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyLR(deg):\n",
    "  return Pipeline([(\"poly\", PolynomialFeatures(degree = deg)),\n",
    "                   (\"LR\", LogisticRegression(penalty = None, max_iter = 1000))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c218f-196e-43ac-ad17-47bd41829581",
   "metadata": {},
   "source": [
    "Now, we can use cross-validation to select which degree (number of polynomial features) works best for our data. The main principle behind cross-validation is that you can divide your training data into $k$ folds (chunks), and then train your model over $k-1$ chunks and then <i>validate</i> it over the last remaining chunk. Therefore, if you divide your training data into $4$ chunks - let us say - then each one of the $4$ chunks will act as the <i>validation data</i> once, with the rest of the chunks being used as <i>training data</i>. Therefore, in case of $4$ chunks, the <u>fit</u> function will be called $4$ times. Now, we can find the <i>mean</i> cross-validation score for varying degrees (number of polynomial features), and the degree which has the highest cross-validation score is most likely to perform the best on the <i>testing data</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cb6ef2b-4b5b-4ce8-9724-b8a73b35a4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Degree = 0, Score = 0.535\n",
      "Polynomial Degree = 1, Score = 0.772\n",
      "Polynomial Degree = 2, Score = 0.811\n",
      "Polynomial Degree = 3, Score = 0.809\n",
      "Polynomial Degree = 4, Score = 0.806\n"
     ]
    }
   ],
   "source": [
    "for deg in range(5):\n",
    "    plr = polyLR(deg = deg)\n",
    "    cv_scores = cross_val_score(plr, X_train, y_train, cv = 5)\n",
    "    mean_score = cv_scores.mean()\n",
    "    print(f\"Polynomial Degree = {deg}, Score = {mean_score.round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20e289-8bde-4b63-832f-fc714ea2ed55",
   "metadata": {},
   "source": [
    "Therefore, for our purposes it seems that Polynomial Degree = $2$ yields the best results during our cross-validation, so we can assume that this degree is also likely to perform the best on our <i>testing data</i>. Now, we can go ahead and create a Logistic Regression model with degrees = $2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75aab2f9-6fcd-4ed2-861d-219e4a7ab278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Training Data: 0.811\n"
     ]
    }
   ],
   "source": [
    "plr = polyLR(deg = 2)\n",
    "plr.fit(X_train, y_train)\n",
    "print(f\"Score on Training Data: {plr.score(X_train, y_train).round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b3b2c-9c86-433a-a97d-c0a33c354743",
   "metadata": {},
   "source": [
    "Now, finally we can check the performance of our model on the <i>testing data</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "070e411d-6a46-42d1-958c-e7a17269b3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Testing Data: 0.811\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score on Testing Data: {plr.score(X_test, y_test).round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af775e-90d4-4c10-ab22-c03b9d034169",
   "metadata": {},
   "source": [
    "Therefore, we can see that we achieved approximately $81$% accuracy on our <i>testing data</i>!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde24106-20ef-4b09-acba-9cd39e72245a",
   "metadata": {},
   "source": [
    "# Auditing the Model \n",
    "Now that our model is trained, we can perform an audit on the test data where we can answer questions on our <i>testing data</i>. It is helpful to use a confusion matrix while answering these questions. A confusion matrix, is a matrix containing information about the model's prediction and the kind of errors it makes: \n",
    "<ol>\n",
    "    <li>True Negative: Negative Data + Classified Negative by Model\n",
    "    <li>False Positive: Negative Data + Wrongly Classified Positive by Model\n",
    "    <li>False Negative: Positive Data + Wrongly Classified Negative by Model\n",
    "    <li>True Positive: Positive Data + Classified Positive by Model\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a654ca6-63bf-4c68-b567-667b320cb972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix:\n",
      " [[16235  4952]\n",
      " [ 2491 15716]]\n",
      "\n",
      "True Negative: 16235\n",
      "False Positive: 4952\n",
      "False Negative: 2491\n",
      "True Positive: 15716\n"
     ]
    }
   ],
   "source": [
    "y_pred = plr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"The Confusion Matrix:\\n {cm}\")\n",
    "tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "print(f\"\\nTrue Negative: {tn}\")\n",
    "print(f\"False Positive: {fp}\")\n",
    "print(f\"False Negative: {fn}\")\n",
    "print(f\"True Positive: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723df0d0-9771-491a-8fec-92fd051144ec",
   "metadata": {},
   "source": [
    "That above is our confusion matrix with the information we talked about above. Now, it is useful to define some concepts and associated formulae:\n",
    "<ol>\n",
    "    <li><u>Overall Accuracy</u>: proportion of correct predictions made over the total number of predictions made <br><br><center>$\\text{Overall Accuracy} = \\frac{TN + TP}{TN + TP + FP + FN}$</center><br>\n",
    "    <li><u>Positive Predictive Value (PPV)</u>: probability that a positive prediction made by the model is actually correct <br><br><center>$\\text{PPV} = \\frac{TP}{TP + FP}$</center><br>\n",
    "    <li><u>False Positive Rate (FPR)</u>: proportion of negative examples that were incorrectly classified as positve<br><br><center>$\\text{FPR} = \\frac{FP}{FP + TN}$</center><br>\n",
    "    <li><u>False Negative Rate (FNR)</u>: proportion of positive examples that were incorrectly classified as negative <br><br><center>$\\text{FNR} = \\frac{FN}{FN + TP}$</center>\n",
    "</ol>\n",
    "\n",
    "### Overall Measures\n",
    "1. What is the overall accuracy of our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45eba11f-cc70-4055-8524-ac8970de9038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of the Model is 81.1%\n"
     ]
    }
   ],
   "source": [
    "overallAccuracy = ((tn + tp)/(tn + tp + fp + fn)).round(3)\n",
    "print(f\"Overall Accuracy of the Model is {np.round(overallAccuracy*100,3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118804a4-41dc-45c2-9732-1495524cf139",
   "metadata": {},
   "source": [
    "2. What is the Positive Predictive Value (PPV) of our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd082aaa-c759-4c2f-9574-6e6fb7d8b232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPV of the Model: 0.76\n",
      "This means that 0.76 of all positive predictions made by the model are actually correct!\n"
     ]
    }
   ],
   "source": [
    "ppv = ((tp)/(tp + fp)).round(3)\n",
    "print(f\"PPV of the Model: {ppv}\")\n",
    "print(f\"This means that {ppv} of all positive predictions made by the model are actually correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f84c35-77c1-48e0-8524-68d5d9221726",
   "metadata": {},
   "source": [
    "3. What are the overall False Positive and False Negative Rates (FPR and FNR) for our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "788d7ef1-f0a3-4290-bbe2-4ff47cb43b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR of the Model: 0.234\n",
      "This means that 0.234 of all negative examples were wrongly classified as positive!\n",
      "\n",
      "FNR of the Model: 0.137\n",
      "This means that 0.137 of all positive examples were wrongly classified as negative!\n"
     ]
    }
   ],
   "source": [
    "fpr = ((fp)/(fp + tn)).round(3)\n",
    "fnr = ((fn)/(fn + tp)).round(3)\n",
    "print(f\"FPR of the Model: {fpr}\")\n",
    "print(f\"This means that {fpr} of all negative examples were wrongly classified as positive!\")\n",
    "print(f\"\\nFNR of the Model: {fnr}\")\n",
    "print(f\"This means that {fnr} of all positive examples were wrongly classified as negative!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f67c04-4e7b-4550-875e-1580d54fb461",
   "metadata": {},
   "source": [
    "### By-Group Measures\n",
    "Now, we can go ahead and look at the: Overall Accuracy, PPV, FPR, and FNR for each the 9 subgroups (the different racial groups). We cannot calculate the statistics for <i>Group 4: Alaskan Natives</i> due to lack of sufficient sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0f548d0-d003-42b6-99b6-257ef91865d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 1:\n",
      "Overall Accuracy: 81.62%\n",
      "PPV of the Model: 0.772\n",
      "This means that 0.772 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.223\n",
      "This means that 0.223 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.139\n",
      "This means that 0.139 of all positive examples were wrongly classified as negative!\n",
      "\n",
      "Group 2:\n",
      "Overall Accuracy: 80.6%\n",
      "PPV of the Model: 0.734\n",
      "This means that 0.734 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.24\n",
      "This means that 0.24 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.133\n",
      "This means that 0.133 of all positive examples were wrongly classified as negative!\n",
      "\n",
      "Group 3:\n",
      "Overall Accuracy: 73.4%\n",
      "PPV of the Model: 0.667\n",
      "This means that 0.667 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.278\n",
      "This means that 0.278 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.25\n",
      "This means that 0.25 of all positive examples were wrongly classified as negative!\n",
      "\n",
      "Group 5:\n",
      "Overall Accuracy: 78.72%\n",
      "PPV of the Model: 0.682\n",
      "This means that 0.682 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.241\n",
      "This means that 0.241 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.167\n",
      "This means that 0.167 of all positive examples were wrongly classified as negative!\n",
      "\n",
      "Group 6:\n",
      "Overall Accuracy: 78.42%\n",
      "PPV of the Model: 0.733\n",
      "This means that 0.733 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.324\n",
      "This means that 0.324 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.107\n",
      "This means that 0.107 of all positive examples were wrongly classified as negative!\n",
      "\n",
      "Group 7:\n",
      "Overall Accuracy: 70.59%\n",
      "PPV of the Model: 0.5\n",
      "This means that 0.5 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.417\n",
      "This means that 0.417 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.0\n",
      "This means that 0.0 of all positive examples were wrongly classified as negative!\n",
      "\n",
      "Group 8:\n",
      "Overall Accuracy: 77.95%\n",
      "PPV of the Model: 0.722\n",
      "This means that 0.722 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.267\n",
      "This means that 0.267 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.164\n",
      "This means that 0.164 of all positive examples were wrongly classified as negative!\n",
      "\n",
      "Group 9:\n",
      "Overall Accuracy: 85.9%\n",
      "PPV of the Model: 0.77\n",
      "This means that 0.77 of all positive predictions made by the model are actually correct!\n",
      "FPR of the Model: 0.144\n",
      "This means that 0.144 of all negative examples were wrongly classified as positive!\n",
      "FNR of the Model: 0.136\n",
      "This means that 0.136 of all positive examples were wrongly classified as negative!\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(1,4)) + list(range(5, 10)):\n",
    "    print(f\"\\nGroup {i}:\")\n",
    "    ix = X_test[group_test == i, :]\n",
    "    y_testx = y_test[group_test == i]\n",
    "    y_predx = plr.predict(ix)\n",
    "    cm = confusion_matrix(y_testx, y_predx)\n",
    "    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]\n",
    "    overallAccuracy = (((tn + tp)/(tn + tp + fp + fn)) * 100).round(2)\n",
    "    ppv = ((tp)/(tp + fp)).round(3)\n",
    "    fpr = ((fp)/(fp + tn)).round(3)\n",
    "    fnr = ((fn)/(fn + tp)).round(3)\n",
    "    print(f\"Overall Accuracy: {overallAccuracy}%\")\n",
    "    print(f\"PPV of the Model: {ppv}\")\n",
    "    print(f\"This means that {ppv} of all positive predictions made by the model are actually correct!\")\n",
    "    print(f\"FPR of the Model: {fpr}\")\n",
    "    print(f\"This means that {fpr} of all negative examples were wrongly classified as positive!\")\n",
    "    print(f\"FNR of the Model: {fnr}\")\n",
    "    print(f\"This means that {fnr} of all positive examples were wrongly classified as negative!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5007b9-121f-469a-97ba-b6fe94b749e8",
   "metadata": {},
   "source": [
    "### Bias Measures\n",
    "##### <font color=\"green\">Is the model approximately <i>calibrated</i>?</font>\n",
    "The results clearly show that the <i>PPV</i> varies across the different racial groups. Therefore, our model is not calibrated. For example, if we compared Group 1 (White only): PPV = $0.772$ and Group 2 (Black only): PPV = $0.734$. Therefore, $\\text{PPV}_\\text{White} > \\text{PPV}_\\text{Black}$, which means that the probability that a positive prediction made by the model is correct, is higher for white people, compared to black people. \n",
    "\n",
    "##### <font color=\"green\">Does the model satisfy approximate <i>error rate balance</i>?</font>\n",
    "The model does not satisfy approximate <i>error rate balance</i>. This is because the <i>FPR</i> and <i>FNR</i> is different across different racial groups. For example, analyzing Group 1 (White only) and Group 2 (Black only): $(\\text{FPR}_\\text{White}  = 0.223) < (\\text{FPR}_\\text{Black}= 0.24)$, and $(\\text{FNR}_\\text{White}  = 0.139) > (\\text{FNR}_\\text{Black}= 0.133)$. Therefore, for FPR: the model is more likely to wrongly classify negative examples (not employed) as positive (employed) for Black people compared to White people. For FNR: the model is more likely to wrongly classify positive examples (employed) as negative (not employed) for White people compared to Black people. Therefore, the model makes different types of mistakes more often, across different racial groups.\n",
    "\n",
    "##### <font color=\"green\">Does the model satisfy <i>statistical parity</i>?</font>\n",
    "Since, our model has different values of <i>PPV</i> for different racial groups - our model does not satisfy <i>statistical parity</i>!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a2ecb-09ad-4d17-99c5-f5f78c6eab4f",
   "metadata": {},
   "source": [
    "# Concluding Discussions\n",
    "##### <font color=\"green\">What groups of people could stand to benefit from a system? hat kinds of companies might want to buy your model for commercial use?</font>\n",
    "Since this model predicts whether a person is employed or not, based on other demographic factors. This model could be used to automate or cross-check the process of providing unemployment benefits to individuals. Since this model is more likely to classify unemployed Black people as employed, and more likely to classify employed White people as unemployed, if there were a model which gave people unemployment benefits based on the results of this model - White people would benefit!\n",
    "\n",
    "##### <font color=\"green\">What could be the impact of deploying your model for large-scale prediction in commercial or governmental settings? Do you feel that your model displays problematic bias?</font>\n",
    "Deploying a model like this for large-scale prediction in commercial or governmental settings will be problematic. This is because, as discussed above: the model will make different kinds of mistakes for different racial groups. Therefore, certain racial groups will benefit more than others - for instance, if the model is used to decide who gets unemployment benefits. Furthermore, this model displays problematic bias. As discussed in the <i>Bias Measures</i> the model is not (does not satisfy):\n",
    "<ol>\n",
    "    <li> Calibrated: probability that a positive prediction made by model is correct is different across racial groups\n",
    "    <li> Approximate Error Rate Balance: will make different kinds of mistakes for different racial groups\n",
    "    <li> Statistical Parity: model does not satisfy Statistical Parity (different <i>PPV</i>) for different racial groups\n",
    "</ol>\n",
    "\n",
    "##### <font color=\"green\">Are there other potential problems associated with deploying your model that make you uncomfortable? How would you propose addressing some of these problems?</font>\n",
    "If this model were to be used for government purposes: deciding unemployment benefits (mentioned above), I would not feel very comfortable. This is because the model first of all has its own problems and biases, and furthermore automating a process which affects an individual (and humans) so much is very inhumane, as the errors of the model can deeply affect people. If the model did not exhibit the problematic biases discussed above, then maybe the model would be slightly better for deployment. However, it would still not be ideal according to me."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
